{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.9.0.80-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in d:\\anaconda3n\\envs\\py310\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Downloading opencv_python-4.9.0.80-cp37-abi3-win_amd64.whl (38.6 MB)\n",
      "   ---------------------------------------- 0.0/38.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/38.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/38.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/38.6 MB 1.0 MB/s eta 0:00:38\n",
      "   ---------------------------------------- 0.2/38.6 MB 1.6 MB/s eta 0:00:25\n",
      "   ---------------------------------------- 0.2/38.6 MB 1.6 MB/s eta 0:00:25\n",
      "    --------------------------------------- 0.5/38.6 MB 2.4 MB/s eta 0:00:17\n",
      "    --------------------------------------- 0.5/38.6 MB 2.4 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 1.0/38.6 MB 3.8 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 1.8/38.6 MB 5.6 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 2.3/38.6 MB 6.6 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 2.3/38.6 MB 6.6 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 2.4/38.6 MB 5.8 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 2.4/38.6 MB 5.8 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 2.7/38.6 MB 5.2 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 3.3/38.6 MB 6.0 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 3.8/38.6 MB 6.4 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 4.6/38.6 MB 7.3 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 4.8/38.6 MB 7.4 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 4.8/38.6 MB 7.4 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 5.0/38.6 MB 6.7 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 5.8/38.6 MB 7.4 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 6.2/38.6 MB 7.7 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 6.4/38.6 MB 7.4 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 6.7/38.6 MB 7.6 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 7.1/38.6 MB 7.7 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 7.2/38.6 MB 7.5 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 7.7/38.6 MB 7.7 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 8.4/38.6 MB 8.0 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 8.7/38.6 MB 8.1 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 9.1/38.6 MB 8.1 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 9.1/38.6 MB 8.1 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 9.6/38.6 MB 8.0 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 10.0/38.6 MB 8.0 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 10.6/38.6 MB 9.5 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 11.0/38.6 MB 9.8 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 11.5/38.6 MB 9.9 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 11.9/38.6 MB 9.8 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 12.6/38.6 MB 9.9 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 12.8/38.6 MB 10.7 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 13.2/38.6 MB 10.7 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 13.7/38.6 MB 10.6 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 14.2/38.6 MB 10.6 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 14.7/38.6 MB 10.2 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 15.3/38.6 MB 11.3 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 15.9/38.6 MB 11.1 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 16.2/38.6 MB 11.3 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 16.7/38.6 MB 11.5 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 16.7/38.6 MB 11.5 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 17.1/38.6 MB 11.1 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 17.3/38.6 MB 11.1 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 17.3/38.6 MB 11.1 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 17.8/38.6 MB 10.6 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 18.1/38.6 MB 10.4 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 18.2/38.6 MB 10.1 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 18.5/38.6 MB 10.2 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 18.5/38.6 MB 10.2 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 19.0/38.6 MB 9.9 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 19.1/38.6 MB 9.8 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 19.1/38.6 MB 9.8 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 19.6/38.6 MB 9.5 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 19.8/38.6 MB 9.5 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 20.6/38.6 MB 9.5 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 21.3/38.6 MB 9.6 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 21.5/38.6 MB 9.5 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 22.4/38.6 MB 9.9 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 22.4/38.6 MB 9.9 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 22.8/38.6 MB 9.4 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 22.8/38.6 MB 9.1 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 23.2/38.6 MB 9.1 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 23.2/38.6 MB 9.0 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 23.6/38.6 MB 9.0 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 23.6/38.6 MB 9.0 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 23.7/38.6 MB 8.3 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 23.9/38.6 MB 8.4 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 23.9/38.6 MB 8.4 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 24.3/38.6 MB 7.9 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 24.6/38.6 MB 7.7 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 24.8/38.6 MB 7.6 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 24.9/38.6 MB 7.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 25.2/38.6 MB 7.2 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 25.4/38.6 MB 7.1 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 25.4/38.6 MB 7.1 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 25.8/38.6 MB 6.8 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 25.8/38.6 MB 6.8 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 26.0/38.6 MB 6.7 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 26.4/38.6 MB 6.5 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 26.4/38.6 MB 6.5 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 26.7/38.6 MB 6.2 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 26.8/38.6 MB 6.2 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 27.0/38.6 MB 6.2 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 27.1/38.6 MB 6.2 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 27.1/38.6 MB 6.2 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 27.5/38.6 MB 6.0 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 27.8/38.6 MB 6.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 28.2/38.6 MB 6.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 28.2/38.6 MB 6.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 28.7/38.6 MB 5.9 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 29.2/38.6 MB 6.2 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 29.6/38.6 MB 6.4 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 29.7/38.6 MB 6.3 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 29.7/38.6 MB 6.3 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 30.2/38.6 MB 6.1 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 30.2/38.6 MB 6.1 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 30.2/38.6 MB 6.1 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 30.5/38.6 MB 5.8 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 30.5/38.6 MB 5.8 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 30.8/38.6 MB 5.5 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 30.8/38.6 MB 5.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 31.0/38.6 MB 5.4 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 31.2/38.6 MB 5.3 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 31.2/38.6 MB 5.3 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 31.5/38.6 MB 5.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 31.5/38.6 MB 5.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 31.8/38.6 MB 5.0 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 31.9/38.6 MB 4.9 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 32.2/38.6 MB 4.7 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 32.2/38.6 MB 4.7 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 32.2/38.6 MB 4.7 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 32.5/38.6 MB 4.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 32.6/38.6 MB 4.5 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 32.9/38.6 MB 4.5 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 32.9/38.6 MB 4.5 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 33.2/38.6 MB 4.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 33.2/38.6 MB 4.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 33.2/38.6 MB 4.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 33.5/38.6 MB 4.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 33.5/38.6 MB 4.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 33.8/38.6 MB 4.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 33.9/38.6 MB 4.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 34.1/38.6 MB 4.1 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 34.3/38.6 MB 4.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 34.4/38.6 MB 4.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.7/38.6 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 35.0/38.6 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 35.3/38.6 MB 4.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 35.7/38.6 MB 4.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 35.9/38.6 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 36.2/38.6 MB 4.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 36.2/38.6 MB 4.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 36.5/38.6 MB 4.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 36.5/38.6 MB 4.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 36.8/38.6 MB 4.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 36.9/38.6 MB 4.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 37.3/38.6 MB 4.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 37.6/38.6 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  37.7/38.6 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.1/38.6 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.1/38.6 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.5/38.6 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.6/38.6 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.6/38.6 MB 4.3 MB/s eta 0:00:00\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.9.0.80\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu\n",
      "  Using cached tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py egg_info did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [44 lines of output]\n",
      "      Traceback (most recent call last):\n",
      "        File \"c:\\Users\\Aneesh PB\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\setuptools\\_vendor\\packaging\\requirements.py\", line 35, in __init__\n",
      "          parsed = _parse_requirement(requirement_string)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"c:\\Users\\Aneesh PB\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\setuptools\\_vendor\\packaging\\_parser.py\", line 64, in parse_requirement\n",
      "          return _parse_requirement(Tokenizer(source, rules=DEFAULT_RULES))\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"c:\\Users\\Aneesh PB\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\setuptools\\_vendor\\packaging\\_parser.py\", line 82, in _parse_requirement\n",
      "          url, specifier, marker = _parse_requirement_details(tokenizer)\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"c:\\Users\\Aneesh PB\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\setuptools\\_vendor\\packaging\\_parser.py\", line 126, in _parse_requirement_details\n",
      "          marker = _parse_requirement_marker(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"c:\\Users\\Aneesh PB\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\setuptools\\_vendor\\packaging\\_parser.py\", line 147, in _parse_requirement_marker\n",
      "          tokenizer.raise_syntax_error(\n",
      "        File \"c:\\Users\\Aneesh PB\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\setuptools\\_vendor\\packaging\\_tokenizer.py\", line 165, in raise_syntax_error\n",
      "          raise ParserSyntaxError(\n",
      "      setuptools.extern.packaging._tokenizer.ParserSyntaxError: Expected end or semicolon (after name and no valid version specifier)\n",
      "          python_version>\"3.7\"\n",
      "                        ^\n",
      "      \n",
      "      The above exception was the direct cause of the following exception:\n",
      "      \n",
      "      Traceback (most recent call last):\n",
      "        File \"<string>\", line 2, in <module>\n",
      "        File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "        File \"C:\\Users\\Aneesh PB\\AppData\\Local\\Temp\\pip-install-tntas5cb\\tensorflow-gpu_c72837edc5f742a482aa65b71aab2b46\\setup.py\", line 40, in <module>\n",
      "          setuptools.setup()\n",
      "        File \"c:\\Users\\Aneesh PB\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\setuptools\\__init__.py\", line 102, in setup\n",
      "          _install_setup_requires(attrs)\n",
      "        File \"c:\\Users\\Aneesh PB\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\setuptools\\__init__.py\", line 73, in _install_setup_requires\n",
      "          dist.parse_config_files(ignore_option_errors=True)\n",
      "        File \"c:\\Users\\Aneesh PB\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\setuptools\\dist.py\", line 629, in parse_config_files\n",
      "          self._finalize_requires()\n",
      "        File \"c:\\Users\\Aneesh PB\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\setuptools\\dist.py\", line 364, in _finalize_requires\n",
      "          self._normalize_requires()\n",
      "        File \"c:\\Users\\Aneesh PB\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\setuptools\\dist.py\", line 379, in _normalize_requires\n",
      "          self.install_requires = list(map(str, _reqs.parse(install_requires)))\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"c:\\Users\\Aneesh PB\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\setuptools\\_vendor\\packaging\\requirements.py\", line 37, in __init__\n",
      "          raise InvalidRequirement(str(e)) from e\n",
      "      setuptools.extern.packaging.requirements.InvalidRequirement: Expected end or semicolon (after name and no valid version specifier)\n",
      "          python_version>\"3.7\"\n",
      "                        ^\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-gpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 0.9142 - accuracy: 0.6272 - val_loss: 0.8045 - val_accuracy: 0.7052\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.6508 - accuracy: 0.7442 - val_loss: 0.6207 - val_accuracy: 0.7919\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.4051 - accuracy: 0.8526 - val_loss: 0.3333 - val_accuracy: 0.8786\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.1810 - accuracy: 0.9350 - val_loss: 0.2200 - val_accuracy: 0.9075\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0947 - accuracy: 0.9725 - val_loss: 0.1179 - val_accuracy: 0.9653\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0298 - accuracy: 0.9942 - val_loss: 0.0751 - val_accuracy: 0.9769\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0088 - accuracy: 0.9986 - val_loss: 0.0731 - val_accuracy: 0.9711\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.0185 - accuracy: 0.9971 - val_loss: 0.0543 - val_accuracy: 0.9769\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0119 - accuracy: 0.9986 - val_loss: 0.0963 - val_accuracy: 0.9538\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0214 - accuracy: 0.9942 - val_loss: 0.1093 - val_accuracy: 0.9769\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0154 - accuracy: 0.9971 - val_loss: 0.0296 - val_accuracy: 0.9827\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.0093 - accuracy: 0.9986 - val_loss: 0.0650 - val_accuracy: 0.9827\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0153 - accuracy: 0.9957 - val_loss: 0.0821 - val_accuracy: 0.9653\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.0274 - val_accuracy: 0.9942\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0131 - accuracy: 0.9971 - val_loss: 0.0352 - val_accuracy: 0.9827\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.0402 - val_accuracy: 0.9827\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.0101 - accuracy: 0.9986 - val_loss: 0.0723 - val_accuracy: 0.9711\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.0250 - accuracy: 0.9942 - val_loss: 0.0881 - val_accuracy: 0.9653\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.0186 - accuracy: 0.9971 - val_loss: 0.0578 - val_accuracy: 0.9884\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0080 - accuracy: 0.9986 - val_loss: 0.0320 - val_accuracy: 0.9884\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.0034 - accuracy: 0.9986 - val_loss: 0.0264 - val_accuracy: 0.9884\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.0040 - accuracy: 0.9986 - val_loss: 0.0437 - val_accuracy: 0.9827\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.0068 - accuracy: 0.9986 - val_loss: 0.0222 - val_accuracy: 0.9884\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.0327 - val_accuracy: 0.9827\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.0282 - val_accuracy: 0.9884\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.0326 - val_accuracy: 0.9884\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.0039 - accuracy: 0.9986 - val_loss: 0.0280 - val_accuracy: 0.9827\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0022 - accuracy: 0.9986 - val_loss: 0.0289 - val_accuracy: 0.9827\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.0015 - accuracy: 0.9986 - val_loss: 0.0457 - val_accuracy: 0.9827\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0064 - accuracy: 0.9986 - val_loss: 0.0290 - val_accuracy: 0.9827\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.0348 - val_accuracy: 0.9827\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.0025 - accuracy: 0.9986 - val_loss: 0.0247 - val_accuracy: 0.9827\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.0014 - accuracy: 0.9986 - val_loss: 0.0353 - val_accuracy: 0.9884\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.0030 - accuracy: 0.9986 - val_loss: 0.0269 - val_accuracy: 0.9827\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.0348 - val_accuracy: 0.9884\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.0033 - accuracy: 0.9986 - val_loss: 0.0304 - val_accuracy: 0.9884\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.9986 - val_loss: 0.0324 - val_accuracy: 0.9884\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0029 - accuracy: 0.9986 - val_loss: 0.0362 - val_accuracy: 0.9884\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.0079 - accuracy: 0.9986 - val_loss: 0.0573 - val_accuracy: 0.9769\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0034 - accuracy: 0.9986 - val_loss: 0.0319 - val_accuracy: 0.9827\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 7.3508e-04 - accuracy: 1.0000 - val_loss: 0.0598 - val_accuracy: 0.9827\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 3.5318e-04 - accuracy: 1.0000 - val_loss: 0.0351 - val_accuracy: 0.9769\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 2.2416e-04 - accuracy: 1.0000 - val_loss: 0.0332 - val_accuracy: 0.9827\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 9.1524e-05 - accuracy: 1.0000 - val_loss: 0.0358 - val_accuracy: 0.9827\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 1.0970e-04 - accuracy: 1.0000 - val_loss: 0.0336 - val_accuracy: 0.9827\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 8.0632e-05 - accuracy: 1.0000 - val_loss: 0.0345 - val_accuracy: 0.9827\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 7.3135e-05 - accuracy: 1.0000 - val_loss: 0.0343 - val_accuracy: 0.9827\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 6.9384e-05 - accuracy: 1.0000 - val_loss: 0.0342 - val_accuracy: 0.9827\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 6.2027e-05 - accuracy: 1.0000 - val_loss: 0.0343 - val_accuracy: 0.9827\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 5.8655e-05 - accuracy: 1.0000 - val_loss: 0.0349 - val_accuracy: 0.9827\n",
      "Epoch 51/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 5.7850e-05 - accuracy: 1.0000 - val_loss: 0.0349 - val_accuracy: 0.9827\n",
      "Epoch 52/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 5.0634e-05 - accuracy: 1.0000 - val_loss: 0.0356 - val_accuracy: 0.9827\n",
      "Epoch 53/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 4.8275e-05 - accuracy: 1.0000 - val_loss: 0.0356 - val_accuracy: 0.9827\n",
      "Epoch 54/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 4.9461e-05 - accuracy: 1.0000 - val_loss: 0.0355 - val_accuracy: 0.9827\n",
      "Epoch 55/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 4.6930e-05 - accuracy: 1.0000 - val_loss: 0.0362 - val_accuracy: 0.9827\n",
      "Epoch 56/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 4.6965e-05 - accuracy: 1.0000 - val_loss: 0.0353 - val_accuracy: 0.9827\n",
      "Epoch 57/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 5.4982e-05 - accuracy: 1.0000 - val_loss: 0.0375 - val_accuracy: 0.9827\n",
      "Epoch 58/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 3.4043e-05 - accuracy: 1.0000 - val_loss: 0.0347 - val_accuracy: 0.9827\n",
      "Epoch 59/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 4.9667e-05 - accuracy: 1.0000 - val_loss: 0.0348 - val_accuracy: 0.9827\n",
      "Epoch 60/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 3.5113e-05 - accuracy: 1.0000 - val_loss: 0.0370 - val_accuracy: 0.9827\n",
      "Epoch 61/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 3.7443e-05 - accuracy: 1.0000 - val_loss: 0.0373 - val_accuracy: 0.9827\n",
      "Epoch 62/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 3.7281e-05 - accuracy: 1.0000 - val_loss: 0.0367 - val_accuracy: 0.9827\n",
      "Epoch 63/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 4.4952e-05 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 0.9827\n",
      "Epoch 64/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 3.1154e-05 - accuracy: 1.0000 - val_loss: 0.0369 - val_accuracy: 0.9827\n",
      "Epoch 65/100\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 3.2839e-05 - accuracy: 1.0000 - val_loss: 0.0367 - val_accuracy: 0.9827\n",
      "Epoch 66/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 3.0338e-05 - accuracy: 1.0000 - val_loss: 0.0373 - val_accuracy: 0.9827\n",
      "Epoch 67/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 2.8268e-05 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9827\n",
      "Epoch 68/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 3.2154e-05 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9827\n",
      "Epoch 69/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 2.5608e-05 - accuracy: 1.0000 - val_loss: 0.0377 - val_accuracy: 0.9827\n",
      "Epoch 70/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 2.8675e-05 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9827\n",
      "Epoch 71/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 2.4568e-05 - accuracy: 1.0000 - val_loss: 0.0377 - val_accuracy: 0.9827\n",
      "Epoch 72/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 2.4565e-05 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9827\n",
      "Epoch 73/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 2.6316e-05 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9827\n",
      "Epoch 74/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 2.4485e-05 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9827\n",
      "Epoch 75/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 2.2807e-05 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9827\n",
      "Epoch 76/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 2.6257e-05 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 0.9827\n",
      "Epoch 77/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 2.0723e-05 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9827\n",
      "Epoch 78/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 2.2773e-05 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9827\n",
      "Epoch 79/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 1.9295e-05 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 0.9827\n",
      "Epoch 80/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 2.1013e-05 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9827\n",
      "Epoch 81/100\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 2.0663e-05 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9827\n",
      "Epoch 82/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 1.8295e-05 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9827\n",
      "Epoch 83/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 1.9671e-05 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 0.9827\n",
      "Epoch 84/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 1.7486e-05 - accuracy: 1.0000 - val_loss: 0.0406 - val_accuracy: 0.9827\n",
      "Epoch 85/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 2.0247e-05 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9827\n",
      "Epoch 86/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 1.5334e-05 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9827\n",
      "Epoch 87/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 1.6831e-05 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 0.9827\n",
      "Epoch 88/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 1.5558e-05 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9827\n",
      "Epoch 89/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 1.5943e-05 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9827\n",
      "Epoch 90/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 1.4958e-05 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 0.9827\n",
      "Epoch 91/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 1.4775e-05 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 0.9827\n",
      "Epoch 92/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 1.4246e-05 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 0.9827\n",
      "Epoch 93/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 1.3507e-05 - accuracy: 1.0000 - val_loss: 0.0430 - val_accuracy: 0.9827\n",
      "Epoch 94/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 1.3653e-05 - accuracy: 1.0000 - val_loss: 0.0441 - val_accuracy: 0.9827\n",
      "Epoch 95/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 1.2397e-05 - accuracy: 1.0000 - val_loss: 0.0434 - val_accuracy: 0.9827\n",
      "Epoch 96/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 1.1974e-05 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 0.9827\n",
      "Epoch 97/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 1.2635e-05 - accuracy: 1.0000 - val_loss: 0.0439 - val_accuracy: 0.9827\n",
      "Epoch 98/100\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 1.1101e-05 - accuracy: 1.0000 - val_loss: 0.0437 - val_accuracy: 0.9827\n",
      "Epoch 99/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 1.1020e-05 - accuracy: 1.0000 - val_loss: 0.0440 - val_accuracy: 0.9827\n",
      "Epoch 100/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 1.1374e-05 - accuracy: 1.0000 - val_loss: 0.0436 - val_accuracy: 0.9827\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "folders = ['Normal cases', 'Bengin cases', 'Malignant cases']\n",
    "\n",
    "# Load the dataset\n",
    "def load_data(data_dir):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for label in folders:\n",
    "        label_path = os.path.join(data_dir, label)\n",
    "        for image_file in os.listdir(label_path):\n",
    "            image_path = os.path.join(label_path, image_file)\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.resize(image, (100, 100))  # Resize the images to a fixed size\n",
    "            images.append(image)\n",
    "            labels.append(label)\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Preprocess the data\n",
    "def preprocess_data(images, labels):\n",
    "    # Encode labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    labels = label_encoder.fit_transform(labels)\n",
    "    num_classes = len(np.unique(labels))\n",
    "    labels = to_categorical(labels, num_classes=num_classes)  # Ensure one-hot encoding with correct number of classes\n",
    "    \n",
    "    # Normalize pixel values\n",
    "    images = images.astype('float32') / 255.0\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "# Define the CNN model\n",
    "def create_model(input_shape, num_classes):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Load the dataset\n",
    "data_dir = \"C:\\\\Users\\\\Aneesh PB\\\\Downloads\\\\Topology Project\\\\Training image\"\n",
    "images, labels = load_data(data_dir)\n",
    "\n",
    "# Preprocess the data\n",
    "images, labels = preprocess_data(images, labels)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(images, labels, test_size=0.2, random_state=2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=2)\n",
    "# Determine the number of classes\n",
    "num_classes = y_train.shape[1] # Determine number of classes from y_train shape\n",
    "\n",
    "# Create the CNN model\n",
    "input_shape = X_train.shape[1:]\n",
    "model = create_model(input_shape, num_classes)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "# Evaluate the model\n",
    "model.save(\"trained_model.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 39ms/step - loss: 0.0356 - accuracy: 0.9862\n",
      "Test accuracy: 0.9861751198768616\n",
      "7/7 [==============================] - 0s 5ms/step\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "   Normal cases       0.91      0.95      0.93        21\n",
      "   Bengin cases       1.00      1.00      1.00       117\n",
      "Malignant cases       0.99      0.97      0.98        79\n",
      "\n",
      "       accuracy                           0.99       217\n",
      "      macro avg       0.97      0.98      0.97       217\n",
      "   weighted avg       0.99      0.99      0.99       217\n",
      "\n",
      "Validation accuracy during training: [0.7052023410797119, 0.7919074892997742, 0.8786126971244812, 0.9075144529342651, 0.9653179049491882, 0.9768785834312439, 0.9710982441902161, 0.9768785834312439, 0.9537572264671326, 0.9768785834312439, 0.9826589822769165, 0.9826589822769165, 0.9653179049491882, 0.9942196607589722, 0.9826589822769165, 0.9826589822769165, 0.9710982441902161, 0.9653179049491882, 0.9884393215179443, 0.9884393215179443, 0.9884393215179443, 0.9826589822769165, 0.9884393215179443, 0.9826589822769165, 0.9884393215179443, 0.9884393215179443, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9884393215179443, 0.9826589822769165, 0.9884393215179443, 0.9884393215179443, 0.9884393215179443, 0.9884393215179443, 0.9768785834312439, 0.9826589822769165, 0.9826589822769165, 0.9768785834312439, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165, 0.9826589822769165]\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "# Generate predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Generate and print classification report\n",
    "report = classification_report(y_true_labels, y_pred_labels, target_names=folders)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# Print validation accuracy during training\n",
    "val_acc = history.history['val_accuracy']\n",
    "print('Validation accuracy during training:', val_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 29ms/step - loss: 0.0461 - accuracy: 0.9770\n",
      "Test accuracy: 0.9769585132598877\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "\n",
    "print('Test accuracy:', test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
